{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6339538,"sourceType":"datasetVersion","datasetId":3649814}],"dockerImageVersionId":30527,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install razdel\n!pip install compress-fasttext","metadata":{"_uuid":"3d10b490-1594-4a73-bf36-55e2b0434a69","_cell_guid":"4dddecb1-87b0-4be7-81bf-602486eba537","execution":{"iopub.status.busy":"2024-02-22T03:42:52.866683Z","iopub.execute_input":"2024-02-22T03:42:52.867582Z","iopub.status.idle":"2024-02-22T03:43:14.985747Z","shell.execute_reply.started":"2024-02-22T03:42:52.867549Z","shell.execute_reply":"2024-02-22T03:43:14.984328Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"from typing import Dict, List, Tuple, Union, Callable, DefaultDict, Optional\nfrom datasets import load_dataset\nfrom razdel import tokenize\nimport string\nfrom tqdm import tqdm\nfrom sklearn.metrics import f1_score\nimport compress_fasttext\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\nfrom random import random","metadata":{"_uuid":"ea54d75d-21b7-44d2-9a65-32a6427e7141","_cell_guid":"516674aa-a3b4-4381-88a3-e8c9513f3b10","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-22T03:27:46.745816Z","iopub.execute_input":"2024-02-22T03:27:46.746145Z","iopub.status.idle":"2024-02-22T03:27:51.322210Z","shell.execute_reply.started":"2024-02-22T03:27:46.746112Z","shell.execute_reply":"2024-02-22T03:27:51.321213Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"truncate = 25\nbatch_size = 32\nembedding_dim = 300\nhidden_size = 128\nnum_layers = 1\ndropout = 0\nbidirectional = True\nlr = 0.001\nweight_decay = 0\namsgrad = False\nclip_grad_norm = 0.1\nn_epoch = 10\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:27:51.323330Z","iopub.execute_input":"2024-02-22T03:27:51.323829Z","iopub.status.idle":"2024-02-22T03:27:51.378477Z","shell.execute_reply.started":"2024-02-22T03:27:51.323804Z","shell.execute_reply":"2024-02-22T03:27:51.377441Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def to_numpy(tensor):\n    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\ndef func(element):\n    del element['relations'], element['links']\n    return element\ndef get_ent_data(ent):\n    ent = ent.split('\\t')\n    words = ent[2]\n    mid = ent[1].split(' ')\n    entity = mid[0]\n    beg = mid[1]\n    end = mid[2]\n    return words, entity, beg, end\n\ndef get_tokens(s):\n    tokens = []\n    for token in tokenize(s.lower()):\n            if token.text in string.punctuation.replace('.', '')+'—«»ъ':\n                pass\n            else:\n                tokens.append(token.text)\n    return tokens\n\ndef preprocess_and_write_in_file(filename, iterator):\n    my_file = open(filename, 'a+')\n    limit = 50\n    for sample in tqdm(iterator):\n        entities = []\n        for ent in sample['entities']:\n            words, entity_name, beg, end = get_ent_data(ent)\n            try:\n                end = int(end)\n            except:\n                continue\n            words_list = words.split(' ')\n            words_list_len = len(words_list)\n            if len(words_list) != 1:\n                for i, the_word in enumerate(words_list):\n                    if i == 0:\n                        entities.append((the_word, 'B_'+entity_name, beg, '-1'))\n                    elif i == words_list_len - 1:\n                        entities.append((the_word, 'E_'+entity_name, '-1', end))\n                    else:\n                        entities.append((the_word, 'M_'+entity_name, '-1', '-1'))\n            else:\n                entities.append((words, entity_name, beg, end))\n\n        tokens = get_tokens(sample['text'])\n\n        result = []\n        for token in tokens:\n            for idx, entity in enumerate(entities):\n                name = entity[1]\n                start = int(entity[2])\n                stop = int(entity[3])\n                if token.start == start or token.stop == stop:\n                    result.append((token.text, name))\n                    break\n                if idx == len(entities)-1:\n                    result.append((token.text, None))\n        for idx in range(1, len(result)):\n            previous_ent_name = str(result[idx-1][1])\n            current_ent_name = str(result[idx][1])\n            current_ent_word = str(result[idx][0])\n            if (previous_ent_name[:2] == 'B_' or previous_ent_name[:2] == 'M_') and current_ent_name == 'None':\n                result[idx] = (current_ent_word,'M_'+previous_ent_name[2:])\n        for idx in range(len(result)):\n            current_ent_name = str(result[idx][1])\n            current_ent_word = str(result[idx][0])\n            if current_ent_name == 'None':\n                result[idx] = (current_ent_word, 'O')\n                continue\n            if current_ent_name[:2] == 'B_':\n                continue\n            if current_ent_name[:2] == 'M_' or current_ent_name[:2] == 'E_':\n                result[idx] = (current_ent_word, 'I_'+current_ent_name[2:])\n                continue\n            result[idx] = (current_ent_word, 'B_'+current_ent_name)\n        \n        for res in result:\n            my_file.write(res[0]+' '+res[1]+'\\n')\ndef to_indexes(element: Tuple[str,str]) -> Tuple[int, int]:\n    word = element[0]\n    label = element[1]\n    if word in token2id:\n        word_id = token2id[word]\n    else:\n        word_id = 0\n    label_id = l2i[label]\n    return word_id, label_id\n    \ndef count_unks(elements: List[Tuple[str, str]]) -> int:\n    counter = 0\n    for element in elements:\n        word_id = element[0]\n        if word_id == 0:\n            counter += 1\n    return counter\n\ndef pad_sentence(sentence, padding = 32):\n    l = len(sentence)\n    if l < padding:\n        return sentence + [(1, 0) for _ in range(padding-l)]\n    else:\n        return sentence[:padding]","metadata":{"_uuid":"0d53b79e-5517-4892-b8b3-e83b77539dd7","_cell_guid":"faaff45a-417c-4614-9c17-526f6c4f2f01","execution":{"iopub.status.busy":"2024-02-22T03:27:51.381750Z","iopub.execute_input":"2024-02-22T03:27:51.382422Z","iopub.status.idle":"2024-02-22T03:27:51.408234Z","shell.execute_reply.started":"2024-02-22T03:27:51.382386Z","shell.execute_reply":"2024-02-22T03:27:51.407212Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"fasttext = compress_fasttext.models.CompressedFastTextKeyedVectors.load(\n    'https://github.com/avidale/compress-fasttext/releases/download/gensim-4-draft/geowac_tokens_sg_300_5_2020-100K-20K-100.bin'\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:27:51.409463Z","iopub.execute_input":"2024-02-22T03:27:51.409892Z","iopub.status.idle":"2024-02-22T03:27:55.827199Z","shell.execute_reply.started":"2024-02-22T03:27:51.409863Z","shell.execute_reply":"2024-02-22T03:27:55.826399Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_data = []\nvalid_data = []\nwith open('/kaggle/input/nerdataset/train_ds.txt') as openfileobject:\n    for line in openfileobject:\n        train_data.append((line[:-1].split(' ')[0], line[:-1].split(' ')[1]))\nwith open('/kaggle/input/nerdataset/val_ds.txt') as openfileobject:\n    for line in openfileobject:\n        valid_data.append((line[:-1].split(' ')[0], line[:-1].split(' ')[1]))\nlabel_names = load_dataset('MalakhovIlya/NEREL', 'ent_types')['ent_types']['type']\n\nprint('TRAIN_DATASET:')\nprint(train_data[20:25], 'etc')\nprint('LABEL_NAMES:') \nprint(label_names[:5], 'etc')","metadata":{"_uuid":"4f26de68-038a-45f6-9a58-36ce327ad1cd","_cell_guid":"53f0cd48-9028-49de-a0fa-13a477997f3a","execution":{"iopub.status.busy":"2024-02-22T03:27:55.828323Z","iopub.execute_input":"2024-02-22T03:27:55.828632Z","iopub.status.idle":"2024-02-22T03:27:57.421726Z","shell.execute_reply.started":"2024-02-22T03:27:55.828594Z","shell.execute_reply":"2024-02-22T03:27:57.420758Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.04k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec0f0db04ab440fbb4fd9b1632565c50"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset nerel_builder/ent_types to /root/.cache/huggingface/datasets/MalakhovIlya___nerel_builder/ent_types/1.1.0/e399bfb732badee345c987fd415ea0b17c085de7bd8c4a85b56d7c5e7205df2a...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07e74197c4954f94904b11c0be8cc507"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.22k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c14e6701f0a541a9b0ec3a2dae2ccf93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating ent_types split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset nerel_builder downloaded and prepared to /root/.cache/huggingface/datasets/MalakhovIlya___nerel_builder/ent_types/1.1.0/e399bfb732badee345c987fd415ea0b17c085de7bd8c4a85b56d7c5e7205df2a. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3e522edf78e4ece88d056bbb3601b53"}},"metadata":{}},{"name":"stdout","text":"TRAIN_DATASET:\n[('правоохранительные', 'B_ORGANIZATION'), ('органы', 'I_ORGANIZATION'), ('киргизии', 'I_ORGANIZATION'), ('обнаружили', 'O'), ('в', 'O')] etc\nLABEL_NAMES:\n['AGE', 'AWARD', 'CITY', 'COUNTRY', 'CRIME'] etc\n","output_type":"stream"}]},{"cell_type":"code","source":"token2count = {}\ntoken2id = {'unk' : 0, 'pad' : 1}\nid2token = {0 : 'unk',1 : 'pad'}\nid2vec = {0 : fasttext.get_mean_vector(list(fasttext.key_to_index)), 1 : fasttext['пикассо']}\n\nfor word, entity_name in train_data+valid_data:\n    if word in token2count:\n        token2count[word] += 1\n    else:\n        token2count[word] = 1    \n\ni = 2\nfor word in token2count:\n    #if token2count[word] > 1 or (token2count[word] == 1 and random() > 0.5):\n    token2id[word] = i\n    id2token[i] = word\n    i+= 1\n    \nfor idx,token in enumerate(token2id):\n    if idx > 1:\n        id2vec[idx] = fasttext[token]\nvocab_size = len(token2id)\n\nl2i = {'O':0}\ni = 1\nfor label in label_names:\n    l2i['B_'+label] = i\n    l2i['I_'+label] = i+1\n    i += 2\ni2l = {v: k for k, v in l2i.items()}","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:27:57.422836Z","iopub.execute_input":"2024-02-22T03:27:57.423109Z","iopub.status.idle":"2024-02-22T03:28:09.560338Z","shell.execute_reply.started":"2024-02-22T03:27:57.423085Z","shell.execute_reply":"2024-02-22T03:28:09.559228Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print('tok2count:', token2count['дом'])\nprint('tok2id:', token2id['дом'])\nprint('id2tok:', id2token[194])\nprint('i2l:', i2l[3])\nprint('l2i:', l2i['B_AWARD'])","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:28:09.561857Z","iopub.execute_input":"2024-02-22T03:28:09.562540Z","iopub.status.idle":"2024-02-22T03:28:09.568777Z","shell.execute_reply.started":"2024-02-22T03:28:09.562501Z","shell.execute_reply":"2024-02-22T03:28:09.567702Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"tok2count: 39\ntok2id: 194\nid2tok: дом\ni2l: B_AWARD\nl2i: 3\n","output_type":"stream"}]},{"cell_type":"code","source":"class NERDataset(Dataset):\n    def __init__(self, dataset: List[Tuple[str, str]]):\n        self.dataset = list(map(to_indexes,dataset))\n        X = []\n        y = []\n        start = 0\n        for idx, (token, label) in enumerate(self.dataset): \n            if token == token2id['.']:\n                padded = pad_sentence(self.dataset[start:idx+1])\n                X.append([padded[i][0] for i in range(len(padded))])\n                y.append([padded[i][1] for i in range(len(padded))])\n                start = idx + 1\n        self.X = X\n        self.y = y\n        \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx: int):\n        return torch.LongTensor(self.X[idx]), torch.LongTensor(self.y[idx])","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:40:09.289008Z","iopub.execute_input":"2024-02-22T03:40:09.289801Z","iopub.status.idle":"2024-02-22T03:40:09.298346Z","shell.execute_reply.started":"2024-02-22T03:40:09.289764Z","shell.execute_reply":"2024-02-22T03:40:09.297380Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"train_ds = NERDataset(train_data)\nvalid_ds = NERDataset(valid_data)\ntrain_loader = DataLoader(\n    dataset = train_ds,\n    batch_size = batch_size,\n    drop_last = True\n)\nvalid_loader = DataLoader(\n    dataset = valid_ds,\n    batch_size = batch_size,\n    drop_last = True\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:28:09.587567Z","iopub.execute_input":"2024-02-22T03:28:09.588561Z","iopub.status.idle":"2024-02-22T03:28:09.920349Z","shell.execute_reply.started":"2024-02-22T03:28:09.588532Z","shell.execute_reply":"2024-02-22T03:28:09.919226Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class EmbeddingPreTrained(nn.Module):\n    \n    def __init__(self, embedding_matrix: np.ndarray, freeze: bool = True):\n        super(EmbeddingPreTrained, self).__init__()\n        \n        self.embedding = nn.Embedding.from_pretrained(\n            torch.tensor(embedding_matrix), \n            freeze = freeze\n        )\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        return self.embedding(x)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:28:09.921579Z","iopub.execute_input":"2024-02-22T03:28:09.921886Z","iopub.status.idle":"2024-02-22T03:28:09.928586Z","shell.execute_reply.started":"2024-02-22T03:28:09.921860Z","shell.execute_reply":"2024-02-22T03:28:09.927389Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class DynamicRNN(nn.Module):\n    def __init__(self,\n                 rnn_unit: nn.Module,\n                 input_size: int,\n                 hidden_size: int,\n                 num_layers: int,\n                 dropout: float,\n                 bidirectional: bool):\n        super(DynamicRNN, self).__init__()\n        self.rnn = rnn_unit(\n            input_size=input_size,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            dropout=dropout,\n            bidirectional=bidirectional,\n            batch_first = True)\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        packed_x = pack_padded_sequence(x, [32 for _ in range(x.size(0))], batch_first = True)\n        packed_rnn_out, hidden = self.rnn(packed_x)\n        rnn_out, _ = pad_packed_sequence(packed_rnn_out, batch_first = True)\n        return rnn_out","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:28:09.929882Z","iopub.execute_input":"2024-02-22T03:28:09.930244Z","iopub.status.idle":"2024-02-22T03:28:09.939155Z","shell.execute_reply.started":"2024-02-22T03:28:09.930204Z","shell.execute_reply":"2024-02-22T03:28:09.937935Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class Attention(nn.Module):\n    def __init__(\n        self,\n        embed_dim: int,\n        num_heads: int,\n        dropout: float\n    ):\n        super(Attention, self).__init__()\n        self.attention = nn.MultiheadAttention(\n            embed_dim = embed_dim,\n            num_heads = num_heads,\n            dropout = dropout)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = x.transpose(0, 1)\n        attn, _ = self.attention(query = x, key = x, value = x)\n        attn = attn.transpose(0, 1)\n        return attn","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:28:09.940388Z","iopub.execute_input":"2024-02-22T03:28:09.940715Z","iopub.status.idle":"2024-02-22T03:28:09.950771Z","shell.execute_reply.started":"2024-02-22T03:28:09.940690Z","shell.execute_reply":"2024-02-22T03:28:09.949681Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class LinearHead(nn.Module):\n    def __init__(self, linear_head: nn.Module):\n        super(LinearHead, self).__init__()\n        self.linear_head = linear_head\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        return self.linear_head(x)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:28:09.952025Z","iopub.execute_input":"2024-02-22T03:28:09.952381Z","iopub.status.idle":"2024-02-22T03:28:09.960308Z","shell.execute_reply.started":"2024-02-22T03:28:09.952357Z","shell.execute_reply":"2024-02-22T03:28:09.959449Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class BiLSTM(nn.Module):\n    def __init__(\n        self,\n        embedding_layer: nn.Module,\n        rnn_layer: nn.Module,\n        #attention_layer: nn.Module,\n        linear_head: nn.Module\n    ):\n        super(BiLSTM, self).__init__()\n        self.embedding = embedding_layer\n        self.rnn = rnn_layer\n        #self.attention = attention_layer\n        self.linear_head = linear_head\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.embedding(x)\n        x = self.rnn(x)\n        #x = self.attention(x)\n        x = self.linear_head(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:28:09.961570Z","iopub.execute_input":"2024-02-22T03:28:09.961887Z","iopub.status.idle":"2024-02-22T03:28:09.969386Z","shell.execute_reply.started":"2024-02-22T03:28:09.961862Z","shell.execute_reply":"2024-02-22T03:28:09.968416Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"embedding_matrix = []\nfor i in range(vocab_size):\n    embedding_matrix.append(id2vec[i])\nembedding_matrix = np.array(embedding_matrix, dtype='float32')\nembeddingLayer = EmbeddingPreTrained(embedding_matrix)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:28:09.970811Z","iopub.execute_input":"2024-02-22T03:28:09.971187Z","iopub.status.idle":"2024-02-22T03:28:10.089576Z","shell.execute_reply.started":"2024-02-22T03:28:09.971156Z","shell.execute_reply":"2024-02-22T03:28:10.088455Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"rnnLayer = DynamicRNN(\n    rnn_unit = nn.GRU,\n    input_size = embedding_dim,\n    hidden_size = hidden_size,\n    num_layers = num_layers,\n    dropout = dropout,\n    bidirectional = bidirectional\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:28:10.090963Z","iopub.execute_input":"2024-02-22T03:28:10.091365Z","iopub.status.idle":"2024-02-22T03:28:10.108034Z","shell.execute_reply.started":"2024-02-22T03:28:10.091337Z","shell.execute_reply":"2024-02-22T03:28:10.107045Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"linearLayer = LinearHead(linear_head = nn.Linear(in_features = 2*hidden_size,out_features = len(l2i)))\n#attentionLayer = Attention(2*hidden_size, num_heads, dropout)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:28:10.109201Z","iopub.execute_input":"2024-02-22T03:28:10.109508Z","iopub.status.idle":"2024-02-22T03:28:10.116964Z","shell.execute_reply.started":"2024-02-22T03:28:10.109484Z","shell.execute_reply":"2024-02-22T03:28:10.115931Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model = BiLSTM(embedding_layer = embeddingLayer,\n               rnn_layer = rnnLayer,\n               #attention_layer = attentionLayer,\n               linear_head = linearLayer).to(device)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:28:10.118476Z","iopub.execute_input":"2024-02-22T03:28:10.118953Z","iopub.status.idle":"2024-02-22T03:28:10.482928Z","shell.execute_reply.started":"2024-02-22T03:28:10.118927Z","shell.execute_reply":"2024-02-22T03:28:10.482120Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def train_epoch(\n    model: nn.Module,\n    dataloader: DataLoader,\n    criterion: Callable,\n    optimizer: torch.optim.Optimizer, \n    device: torch.device,\n    clip_grad_norm: float\n):\n    model.train()\n    losses = []\n    scores = []\n    for x,y in dataloader:\n        x = x.to(device)\n        y = y.to(device)\n        out = model(x)\n        loss = criterion(out.transpose(-1, -2), y)\n        loss.backward()\n        nn.utils.clip_grad_norm_(\n            model.parameters(),\n            max_norm = clip_grad_norm,\n            norm_type = 2)\n        optimizer.step()\n        optimizer.zero_grad()\n        y_true = to_numpy(y)\n        y_pred = np.argmax(to_numpy(out), axis = -1)\n        losses.append(loss.item())\n        scores.append(f1_score(y_true = y_true.flatten(), y_pred = y_pred.flatten(), average = 'weighted'))\n    return np.mean(losses), np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:28:10.484213Z","iopub.execute_input":"2024-02-22T03:28:10.484617Z","iopub.status.idle":"2024-02-22T03:28:10.494010Z","shell.execute_reply.started":"2024-02-22T03:28:10.484584Z","shell.execute_reply":"2024-02-22T03:28:10.492905Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def validate_epoch(\n    model: nn.Module,\n    dataloader: DataLoader,\n    criterion: Callable,\n    device: torch.device\n):\n    model.eval()\n    losses = []\n    scores = []\n    for x,y in dataloader:\n        idx = 6\n        x = x.to(device)\n        y = y.to(device)\n        with torch.no_grad():\n            out = model(x)\n            loss = criterion(out.transpose(-2, -1), y)\n        y_true = to_numpy(y)\n        y_pred = np.argmax(to_numpy(out), axis = -1)\n        #for k in range(32):\n        #    print(id2token[x[idx][k].item()], i2l[y[idx][k].item()], i2l[y_pred[idx][k]])\n        losses.append(loss.item())\n        scores.append(f1_score(y_true = y_true.flatten(), y_pred = y_pred.flatten(), average = 'weighted'))\n    return np.mean(losses), np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:28:10.495251Z","iopub.execute_input":"2024-02-22T03:28:10.495545Z","iopub.status.idle":"2024-02-22T03:28:10.506416Z","shell.execute_reply.started":"2024-02-22T03:28:10.495517Z","shell.execute_reply":"2024-02-22T03:28:10.505532Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def train(\n    model: nn.Module, \n    train_loader: DataLoader,\n    valid_loader: DataLoader,\n    criterion: Callable,\n    optimizer: torch.optim.Optimizer,\n    device: torch.device,\n    clip_grad_norm: float,\n    n_epoch: int,\n    verbose: bool = True\n):\n    for epoch in range(n_epoch):\n        if verbose:\n            print('epoch:', epoch)\n        train_metrics = train_epoch(\n            model = model,\n            dataloader = train_loader,\n            criterion = criterion,\n            optimizer = optimizer,\n            device = device,\n            clip_grad_norm = clip_grad_norm)\n        if verbose:\n            print('train_metrics:', train_metrics)\n        valid_metrics = validate_epoch(\n            model = model,\n            dataloader = valid_loader,\n            criterion = criterion,\n            device = device)\n        if verbose:\n            print('valid_metrcs:', valid_metrics)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:28:10.507577Z","iopub.execute_input":"2024-02-22T03:28:10.507904Z","iopub.status.idle":"2024-02-22T03:28:10.517605Z","shell.execute_reply.started":"2024-02-22T03:28:10.507855Z","shell.execute_reply":"2024-02-22T03:28:10.516722Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"train(model = model,\n      train_loader = train_loader,\n      valid_loader = valid_loader,\n      criterion = criterion,\n      optimizer = torch.optim.Adam(params = model.parameters(),\n                                   lr = lr, weight_decay = weight_decay, \n                                   amsgrad = amsgrad),\n      device = device,\n      clip_grad_norm = clip_grad_norm,\n      n_epoch = n_epoch)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:28:10.518795Z","iopub.execute_input":"2024-02-22T03:28:10.519111Z","iopub.status.idle":"2024-02-22T03:28:36.036946Z","shell.execute_reply.started":"2024-02-22T03:28:10.519086Z","shell.execute_reply":"2024-02-22T03:28:36.035907Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"epoch: 0\ntrain_metrics: (0.62878701522036, 0.8239779305785878)\nvalid_metrcs: (0.3630113892066173, 0.8814987798913783)\nepoch: 1\ntrain_metrics: (0.31474846685335184, 0.8975659570426273)\nvalid_metrcs: (0.3018117409486037, 0.899474351384861)\nepoch: 2\ntrain_metrics: (0.26380026021858505, 0.9129870542471878)\nvalid_metrcs: (0.2777468367264821, 0.9073915741946922)\nepoch: 3\ntrain_metrics: (0.23265961722928993, 0.9225636692320576)\nvalid_metrcs: (0.2656653997225639, 0.9119592699360454)\nepoch: 4\ntrain_metrics: (0.20917786550004383, 0.9301064086429867)\nvalid_metrcs: (0.25935049718007064, 0.9150121148283549)\nepoch: 5\ntrain_metrics: (0.1893832782385242, 0.9366837356983286)\nvalid_metrcs: (0.2566666677594185, 0.916381345317771)\nepoch: 6\ntrain_metrics: (0.1714846767437228, 0.9428216003650559)\nvalid_metrcs: (0.256955603376413, 0.9170873969641647)\nepoch: 7\ntrain_metrics: (0.1546484922744645, 0.9485531356798376)\nvalid_metrcs: (0.26032004696436417, 0.9170569705128366)\nepoch: 8\ntrain_metrics: (0.13866262759570142, 0.9543168975443566)\nvalid_metrcs: (0.26654063107875675, 0.9169343250684846)\nepoch: 9\ntrain_metrics: (0.12339460565873281, 0.9600255275967295)\nvalid_metrcs: (0.2752618256669778, 0.9162506768998488)\n","output_type":"stream"}]},{"cell_type":"code","source":"examples = ['Я на днях побывал в Нижнем Новгороде и меня встретил местный администратор.',\n            'В 12 вечера ко мне приехал сантехник Алексей и рассказал о том, что его сын болеет ветрянкой.',\n            'На улице Ильича открылась новая компания по очистке воды \"Байкал\".',\n            'В российском посольстве в США произошел теракт с использованием химического оружия.',\n            'Якутский спортсмен занял третье место в соревнованиях по стрельбе из лука в Токио на прошлой неделе.',\n            'Американский боксер Мохаммед Али умер в 2016 году от болезни Паркинсона.']","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:32:56.153237Z","iopub.execute_input":"2024-02-22T03:32:56.153620Z","iopub.status.idle":"2024-02-22T03:32:56.158799Z","shell.execute_reply.started":"2024-02-22T03:32:56.153590Z","shell.execute_reply":"2024-02-22T03:32:56.157799Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"example = examples[4]\nexample_ds = []\nfor token in get_tokens(example):\n    example_ds.append((token, 'O'))\nexample_dataset = NERDataset(example_ds)\nexample_loader = DataLoader(dataset = example_dataset)\nfor x,y in example_loader:\n    x = x.to(device)\n    y = y.to(device)\n    with torch.no_grad():\n        out = model(x)\n        loss = criterion(out.transpose(-2, -1), y)\n    y_true = to_numpy(y)\n    y_pred = np.argmax(to_numpy(out), axis = -1)\n    for k in range(32):\n        print(id2token[x[0][k].item()], i2l[y_pred[0][k]])\n    break","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:40:46.765136Z","iopub.execute_input":"2024-02-22T03:40:46.765509Z","iopub.status.idle":"2024-02-22T03:40:46.780166Z","shell.execute_reply.started":"2024-02-22T03:40:46.765480Z","shell.execute_reply":"2024-02-22T03:40:46.779173Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"unk O\nспортсмен B_PROFESSION\nзанял O\nтретье B_ORDINAL\nместо I_AWARD\nв O\nсоревнованиях B_EVENT\nпо I_EVENT\nстрельбе I_EVENT\nиз I_EVENT\nunk I_EVENT\nв O\nтокио B_CITY\nна B_DATE\nпрошлой I_DATE\nнеделе I_DATE\n. O\npad O\npad O\npad O\npad O\npad O\npad O\npad O\npad O\npad O\npad O\npad O\npad O\npad O\npad O\npad O\n","output_type":"stream"}]}]}